{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf518bf",
   "metadata": {},
   "source": [
    "# House Pricing Predictive Model Labwork using Linear Regression (Together with implementing regularization and hyperparameters tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc8003c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import warnings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwarnings\u001b[49m\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Import necessary packages for data analysis and visualization (numpy & pandas)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import necessary packages for data analysis and visualization (numpy & pandas)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import packages for data visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff53fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d52772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "housing = pd.DataFrame(pd.read_csv(\"House Pricing.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first five rows of dataset\n",
    "housing.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the rows and columns of dataset in the format (rows,column)\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c40d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various statistics such as count, mean, standard deviation, minimum, maximum, and percentiles for each numerical column of the dataset\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null values\n",
    "housing.isnull().sum()*100/housing.shape[0]\n",
    "# If output = 0.0, no missing value present in particular column\n",
    "# If output > 0.0, missing values are present in the particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8913323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of distribution of housing features (columns) and to identify potential outliers\n",
    "# Outliers can be identified as individual points outside the whiskers of the boxplots.\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(x=housing['price'], ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Price')\n",
    "axs[0, 0].set_ylabel('Price')\n",
    "\n",
    "sns.boxplot(x=housing['area'], ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Area')\n",
    "axs[0, 1].set_ylabel('Area')\n",
    "\n",
    "sns.boxplot(x=housing['bedrooms'], ax=axs[0, 2])\n",
    "axs[0, 2].set_title('Bedrooms')\n",
    "axs[0, 2].set_ylabel('Bedrooms')\n",
    "\n",
    "sns.boxplot(x=housing['bathrooms'], ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Bathrooms')\n",
    "axs[1, 0].set_ylabel('Bathrooms')\n",
    "\n",
    "sns.boxplot(x=housing['stories'], ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Stories')\n",
    "axs[1, 1].set_ylabel('Stories')\n",
    "\n",
    "sns.boxplot(x=housing['parking'], ax=axs[1, 2])\n",
    "axs[1, 2].set_title('Parking')\n",
    "axs[1, 2].set_ylabel('Parking')\n",
    "\n",
    "fig.suptitle('Distribution of Housing Features (to identify outliers)')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53802814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed to treating outliers\n",
    "# After analyzing the data, it was found that the columns \"Price\" and \"Area\" have a significant number of outliers (many individual points outside the boxplot's whiskers)\n",
    "# As we have a sufficient amount of data, it is possible to drop these outliers  (extreme values) to improve the accuracy of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd5475",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Boxplot(price) with outliers\n",
    "plt.title(\"Boxplot of price with outliers\")\n",
    "plt.boxplot(housing.price)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44036f96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate IQR and bounds for price\n",
    "q1_price = housing.price.quantile(0.25)\n",
    "q3_price = housing.price.quantile(0.75)\n",
    "iqr_price = q3_price - q1_price\n",
    "upper_bound_price = q3_price + 1.5 * iqr_price\n",
    "lower_bound_price = q1_price - 1.5 * iqr_price\n",
    "# Removing outliers/extreme values (lie beyond the whiskers of the boxplot) for price\n",
    "housing = housing[(housing.price >= lower_bound_price) & (housing.price <= upper_bound_price)]\n",
    "plt.boxplot(housing.price)\n",
    "plt.title(\"Boxplot of price with some outliers removed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot(area) with outliers\n",
    "plt.title(\"Boxplot of area with outliers\")\n",
    "plt.boxplot(housing.area)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR and bounds for area\n",
    "q1_area = housing.area.quantile(0.25)\n",
    "q3_area = housing.area.quantile(0.75)\n",
    "iqr_area = q3_area - q1_area\n",
    "upper_bound_area = q3_area + 1.5 * iqr_area\n",
    "lower_bound_area = q1_area - 1.5 * iqr_area\n",
    "# Removing outliers/extreme values (lie beyond the whiskers of the boxplot) for area\n",
    "housing = housing[(housing.area >= lower_bound_area) & (housing.area <= upper_bound_area)]\n",
    "plt.title(\"Boxplot of area with some outliers removed\")\n",
    "plt.boxplot(housing.area)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475310f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b03c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x3 grid of plots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(x=housing['price'], ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Price') \n",
    "axs[0, 0].set_ylabel('Price')  \n",
    "\n",
    "sns.boxplot(x=housing['area'], ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Area')\n",
    "axs[0, 1].set_ylabel('Area')\n",
    "\n",
    "sns.boxplot(x=housing['bedrooms'], ax=axs[0, 2])\n",
    "axs[0, 2].set_title('Bedrooms')\n",
    "axs[0, 2].set_ylabel('Bedrooms')\n",
    "\n",
    "sns.boxplot(x=housing['bathrooms'], ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Bathrooms')\n",
    "axs[1, 0].set_ylabel('Bathrooms')\n",
    "\n",
    "sns.boxplot(x=housing['stories'], ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Stories')\n",
    "axs[1, 1].set_ylabel('Stories')\n",
    "\n",
    "sns.boxplot(x=housing['parking'], ax=axs[1, 2])\n",
    "axs[1, 2].set_title('Parking')\n",
    "axs[1, 2].set_ylabel('Parking')\n",
    "\n",
    "\n",
    "fig.suptitle('Distribution of Housing Features')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23625626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot visualization to show relationship between numeric variables in dataset\n",
    "sns.pairplot(housing, height=2.5)\n",
    "plt.suptitle(\"Relationship between numeric variables\", y=1.05, fontweight= 'bold', fontsize= 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cbe092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to show relationship between categorical data and price\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x = 'mainroad', y = 'price', data = housing)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x = 'guestroom', y = 'price', data = housing)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x = 'basement', y = 'price', data = housing)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x = 'hotwaterheating', y = 'price', data = housing)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x = 'airconditioning', y = 'price', data = housing)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x = 'furnishingstatus', y = 'price', data = housing)\n",
    "plt.title('Furnishing Status vs Price')\n",
    "plt.suptitle(\"Relationship between Categorical Variables and Price\", y=1.0, fontweight='bold', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 6 columns of variables in the dataset with values as 'Yes' or 'No'\n",
    "# Have to convert them to 1s and 0s because numerical values is needed\n",
    "# 1 - Yes ; 0 - No\n",
    "# Here is another view on snippets of the dataset\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting how many Yes and No are in each of these 6 columns of variables with string values.\n",
    "yes_no_cols = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "for col in yes_no_cols:\n",
    "    print(f\"{col}:\")\n",
    "    print(housing[col].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 columns of variables with 'Yes' or 'No' values\n",
    "\n",
    "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "\n",
    "housing[varlist] = housing[varlist].apply(lambda x: x.map({'yes': 1, \"no\": 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display modified dataset\n",
    "housing.head()\n",
    "# In this modified dataset, the 'Yes' has been changed with 1 and the 'No' has been changed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables into numerical variables\n",
    "furnishing_status = pd.get_dummies(housing['furnishingstatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset of furnishing status\n",
    "furnishing_status.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c223ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to the original housing dataset\n",
    "housing = pd.concat([housing, furnishing_status ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'furnishingstatus' column as we already have the converted numerical variables of the furnishing status\n",
    "\n",
    "housing.drop(['furnishingstatus'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaab235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display latest dataset\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(housing, train_size = 0.7, test_size = 0.3, random_state = 100)\n",
    "# Using 80:20 split (70% for training and 30% for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38afee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "# Scaling the numeric variables\n",
    "numericVars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']\n",
    "\n",
    "df_train[numericVars] = scaler.fit_transform(df_train[numericVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d884484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap from Seaborn library used to show the correlation between each variables\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(df_train.corr(), annot=True, cmap=\"Blues\")\n",
    "plt.title(\"Correlation heatmap between each variables\" , fontsize = 18 , fontweight= 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see in this heatmap, the darker the colour of the cell, the higher the value of correlation coefficient between the two variables\n",
    "# In other words, darker colour cell ---> the two variables are highly correlated\n",
    "# In this heatmap, the 1s are not counted, so the variables with highest correlation coefficient are Price and Area (0.56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train, x_vars=['area'], y_vars=['price'], height=5)\n",
    "plt.title('Pairplot between Price and Area', y= 1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('price')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d23a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RFE and Linear Regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a linear regression model to the training data X_train and y_train for predictions on test data.\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887836bb",
   "metadata": {},
   "outputs": [],
   "source": [
    " # running RFE (Feature selection method used to select the best subset of features for a machine learning model)\n",
    "rfe = RFE(estimator=lm, n_features_to_select=6)\n",
    "orient='h'    \n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee992a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5854b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test dataframe with RFE selected variables\n",
    "X_train_rfe = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant variable \n",
    "import statsmodels.api as sm  \n",
    "X_train_rfe = sm.add_constant(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da04e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the linear regression model\n",
    "lm = sm.OLS(y_train,X_train_rfe).fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ea03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of linear regression model\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f25ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the VIFs for the model\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad7f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "X = X_train_rfe\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3245df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of train data\n",
    "y_train_price = lm.predict(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa90a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (y_train_price - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ad335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_price), bins = 20)\n",
    "fig.suptitle('Histogram of Error Terms', fontsize = 20)                 \n",
    "plt.xlabel('Errors', fontsize = 14)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62137936",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_train,res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select a different set of features\n",
    "features = ['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'airconditioning','hotwaterheating', 'parking', 'prefarea','furnished','semi-furnished']\n",
    "# Through trial and error and analysis on the heatmap, the closer the correlation coefficient to 1 or -1 ---> better\n",
    "# As the correlation coefficient of unfurnished to price is -0.28 which is far from -1 and 1, the feature is not selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56929d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(housing[features + ['price']], train_size = 0.7, test_size = 0.3, random_state = 100)\n",
    "# Going with the 70:30 approach for this dataset after trial and errors\n",
    "# 70% is used for training set and 30% is used for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639cce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical variables using MinMaxScaler (unfurnished is dropped)\n",
    "scaler = MinMaxScaler()\n",
    "numericVars = housing.select_dtypes(np.number).drop('unfurnished', axis=1).columns.tolist()\n",
    "df_train[numericVars] = scaler.fit_transform(df_train[numericVars])\n",
    "df_test[numericVars] = scaler.transform(df_test[numericVars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29db0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the predictor variables and the target variable for both training and testing sets\n",
    "y_train = df_train.pop('price')\n",
    "X_train = df_train\n",
    "y_test = df_test.pop('price')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e8832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit a linear regression model on the training data using the selected features\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111615f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable for the testing data using the fitted model\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going with the Ridge regularization instead of Lassso regulariztion after trial and errors.\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to set to find the best alpha value from range of 0.001 to 10.\n",
    "alpha_range = list(np.arange(0.001, 10, 0.1))\n",
    "\n",
    "\n",
    "params = {'alpha': alpha_range}\n",
    "\n",
    "# Create a GridSearchCV object with the Ridge regression model and the hyperparameters to tune\n",
    "grid_search = GridSearchCV(Ridge(), param_grid=params, scoring='r2')\n",
    "\n",
    "# Fit the GridSearchCV object on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters is alpha value (set to 1 d.p)\n",
    "alpha_value = round(grid_search.best_params_['alpha'], 1)\n",
    "print(\"Best hyperparameters (best alpha value):\", alpha_value)\n",
    "\n",
    "# Predict the target variable for the testing data using the best fitted model found by the GridSearchCV object\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear regression models, common evaluation metrics include mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), and R2 score (R-squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "# After getting the best alpha value, it is implemented in the Ridge regularization (which is 1.7 as stated above ^)\n",
    "alpha = 1.7\n",
    "\n",
    "ridge = Ridge(alpha=alpha)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the testing data using the fitted model\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# R-squared score for evaluation of model (set to 4 d.p)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 score with Ridge regression: {:.4f}\".format(r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47318a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculating MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculating RMSE (Root Mean Square Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Mean Absolute Error(MAE):\", round(mae, 4))\n",
    "print (\"Mean Squared Error(MSE):\", round(mse,4))\n",
    "print(\"Root Mean Squared Error(RMSE):\", round(rmse, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0edef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting test values vs predicted values\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test,y_pred) \n",
    "fig.suptitle('Test Values vs Predicted Values', fontsize=20)\n",
    "plt.xlabel('Test values', fontsize=18)\n",
    "plt.ylabel('Predicted value', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d2196",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a line chart\n",
    "fig, ax = plt.subplots()\n",
    "scores = [mae, mse, rmse, r2]\n",
    "labels = ['MAE', 'MSE', 'RMSE', 'R2']\n",
    "colors = ['teal', 'orange', 'yellow', 'pink']\n",
    "ax.bar(labels, scores, color=colors)\n",
    "ax.set_ylabel('Scores' ,fontsize = 10)\n",
    "ax.set_xlabel('Evaluation Metrics', fontsize = 10)\n",
    "ax.set_title('Model Evaluation Scores', y = 1.08, fontsize= 18, fontweight= 'bold')\n",
    "\n",
    "# Add value labels to the top of each bar chart\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(i, v, str(round(v, 4)), ha='center', va='bottom', fontweight= 'bold')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
